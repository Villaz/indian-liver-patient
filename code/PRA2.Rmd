---
title: "PRA2"
author: "Luis Villazón Esteban (LVE), Jose Javier Marti Camarasa (JJMC)"
date: "05/01/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
#sexoknitr::opts_chunk$set(echo = TRUE)
#if(!require(devtools)) install.packages("devtools")
#devtools::install_github("kassambara/ggcorrplot")
library(dplyr)
library(gmodels)
library(ggcorrplot)
library(caret)
library(pROC)
library(varhandle)
library(ResourceSelection)
```

# Enlace GitHub :
## [Practica 2] https://github.com/Villaz/indian-liver-patient

# 1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

El dataset seleccionado contiene datos referentes a pacientes Indios que sufren de Hígado. El problema que se pretende responder con los datos facilitados es la clasificación de pacientes para saber si en función de sus múltiples atributos es un paciente que sufre de Hígado o no.
Para ello el dataset nos ofrece 583 pacientes, de los cuales 416 se encuentran identificados como pacientes que sufren de Hígado y 167 como pacientes que no tienen problemas relacionados con el mismo.

El dataset contiene los siguientes atributos:

- **age**: Edad del paciente, todo aquel paciente cuya edad sea superior a 89 es marcado como 90.
- **gender** Sexo del paciente.
- **tot_bilirubin** Bilirubina Total.
- **direct_bilirubin** Bilirubina en sangre.
- **alkphos** Fosfatasa Alcalina(Niveles altos pueden indicar daño en el hígado).
- **sgpt** Test Alamina aminotransferasa: Test sanguineo para comprobar si hay daño en hígado.
- **sgot** Test Aspartato Aminotransferasa: Test sanguineo para comprobar si hay daño en hígado.
- **tot_proteins** Proteinas totales.
- **albumin** Albumina.
- **ag_ratio** A/G Ratio Albumina y Globulina (Grupo de proteinas solubles en sangre)
- **is_patient** Selector usado para indicar si es paciente de higado. 1 significa si, 2 significa no.

# 2. Integración y selección de los datos de interés a analizar.

En primer lugar realizamos la carga del dataset en R y transformamos la variable dependiente a tipo factor, transformando el valor 1 a "si_padece" y el valor 2 a "no_padece".

```{r}
ilpd_data <- read.csv("../data/ilpd_data.csv",header = FALSE, col.names = c("edad","sexo","TB","DB","alk_phos","alamine","aspartate","TP","albumin","A/G","Padece" ), na="NA", stringsAsFactors = TRUE )

ilpd_data <- ilpd_data%>% mutate(
    Padece = as.factor(case_when(
      Padece == "1"  ~ "si_padece",
      Padece == "2" ~ "no_padece"
           ))
)

```

A continuación mostramos un resumen y una descripción de los valores del dataset.

```{r}
summary(ilpd_data)
```


```{r}
str(ilpd_data)
```

Podemos comprobar como todos los valores son númericos continuos excepto las varibles **sexo** y **Padece** las cuales son categorícas y se han detectado correctamente.



# 3. Limpieza de los datos.

## 3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

Según lo observado anteriormente con el uso del método **summary**, no tenemos ninguna variable con datos perdidos. 
Para tener una visión más clara sobre ello podemos mostrar el número de elementos nulos que existe en cada variable.
```{r}
sort(colMeans(is.na(ilpd_data)), decreasing = TRUE)
```

Efectivamente no tenemos nigun variable con datos perdidos. La funcion colMeans,nos muestra qué proporción de datos no disponibles tenemos por columna.

Disponemos por tanto de un data frame formado por 2 variables categóricas y 8 variables exceptuando la variable objetivo, sin valores nulos

## 3.2. Identificación y tratamiento de valores extremos.

Para identificar los valores extremos vamos a utilizar diagramas de cajas.

```{r}
library("ggplot2")

ggplot(ilpd_data, aes(y=edad)) + geom_boxplot()
ggplot(ilpd_data, aes(y=TB)) + geom_boxplot()
ggplot(ilpd_data, aes(y=DB)) + geom_boxplot()
ggplot(ilpd_data, aes(y=alk_phos)) + geom_boxplot()
ggplot(ilpd_data, aes(y=alamine)) + geom_boxplot()
ggplot(ilpd_data, aes(y=TP)) + geom_boxplot()
ggplot(ilpd_data, aes(y=albumin)) + geom_boxplot()
ggplot(ilpd_data, aes(y=A.G)) + geom_boxplot()
```
Se pueden adivinar posibles outliers o valores extremos. Con un conocimiento del dominio, se podría ver si son susceptibles de quitar o no. Para este análisis los dejaremos por desconocimiento de del dominio.


# 4. Análisis de los datos.

## 4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

De todos los datos que disponemos, como hemos comentado en el punto 3.1 hay dos variables categóricas que necesitaremos binarizar par poder incluirlas en análsis posteriores como por ejemplo el análisis de correlación.
```{r}
a= model.matrix(~Padece, ilpd_data)
p <- as.data.frame(model.matrix(~Padece, ilpd_data))
sexo <- as.data.frame(model.matrix(~sexo, ilpd_data))
ilpd_data['padece'] <- p$Padecesi_padece
ilpd_data['hombre'] <- sexo$sexoMale

str(ilpd_data)
```
Ahora vemos como hemos obtenido dos nuevas columnas binarizada *padece* y *hombre*


## 4.2. Comprobación de la normalidad y homogeneidad de la varianza.

### Comprobación de Normalidad
Primeramente vamos a realizar unas inspecciones visuales sobre la normalidad o no de las variables independientes

```{r}
par(mfrow=c(4,3))
#Variable Edad
ggplot(data=ilpd_data, aes(x=edad )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 

  labs(title="Histograma para Edad", x="Edad", y="Count")

#Variable TB
ggplot(data=ilpd_data, aes(x=TB )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 
 
  labs(title="Histograma para TB", x="TB", y="Count")

#Variable DB
ggplot(data=ilpd_data, aes(x=DB )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 

  labs(title="Histograma para DB", x="DB", y="Count")

#Variable alk_phos
ggplot(data=ilpd_data, aes(x=alk_phos )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 

  labs(title="Histograma para alk_phos", x="alk_phos", y="Count")

#Variable alamine  
ggplot(data=ilpd_data, aes(x=alamine   )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 

  labs(title="Histograma para alamine  ", x="alamine  ", y="Count")

#Variable aspartate  
ggplot(data=ilpd_data, aes(x=aspartate )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 

  labs(title="Histograma para aspartate  ", x="aspartate  ", y="Count")

      
#Variable TP  
ggplot(data=ilpd_data, aes(x=TP )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 

  labs(title="Histograma para TP  ", x="TP  ", y="Count")

#Variable albumin
ggplot(data=ilpd_data, aes(x=albumin )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 

  labs(title="Histograma para Albumin  ", x="Albumin", y="Count")

#Variable A.G.
ggplot(data=ilpd_data, aes(x=A.G )) + 
  geom_histogram(aes(y =..count..), 
                 breaks=seq(1, 100, by = 5), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + 

  labs(title="Histograma para A.G.  ", x="A.G.", y="Count")
          
```

Ya con las gráficas tenemos una *aproximación visual*, y podemos comprobar que la unica variable que podría seguir una distribución normal es la *Edad*.

Vamos a reforzar esta teoria, aplicando el test de *Anderson Darling* para comprobar la normalidad.
```{r}
library(nortest)
alpha = 0.05
col.names = colnames(ilpd_data)
for (i in 1:ncol(ilpd_data)) {
if (i == 1) cat("Variables que no siguen una distribución normal:\n")
if (is.integer(ilpd_data[,i]) | is.numeric(ilpd_data[,i])) {
p_val = ad.test(ilpd_data[,i])$p.value
if (p_val < alpha) {
cat(col.names[i])
# Format output
if (i < ncol(ilpd_data) - 1) cat(", ")
if (i %% 3 == 0) cat("\n")
}
}
}
```

Después de realizar los tests, comprobamos que ninguna variable siguen la Distribucion Normal. Muchas veces las gráficas nos *engañan* a la vista y es necesario realizar pruebas mas profundas

### Comprobación de Homocedasticidad
Seguidamente, pasamos a estudiar la homogeneidad de varianzas mediante la aplicación de un test de *Fligner-Killeen*, ya que las variables no siguen una distribución normal.
Si hubieran seguido una distribucion se habria podido utilizar el *Test de Levene*.

En este caso, estudiaremos esta homogeneidad en cuanto a los grupos de variables contra la variable *Padece*. En el siguiente test, la *hipótesis nula* consiste en que ambas varianzas son iguales.

```{r}
#Variable Edad
fligner.test(edad ~ Padece , data = ilpd_data)

#Variable TB
fligner.test(TB  ~ Padece , data = ilpd_data)

#Variable DB
fligner.test( DB  ~ Padece , data = ilpd_data)

#Variable Alk-Phos
fligner.test(alk_phos  ~ Padece , data = ilpd_data)

#Variable Alamine
fligner.test(alamine  ~ Padece , data = ilpd_data)

#Variable Aspartate
fligner.test(aspartate  ~ Padece , data = ilpd_data)

#Variable Tp
fligner.test(TP  ~ Padece , data = ilpd_data)

#Variable albumine
fligner.test(albumin  ~ Padece , data = ilpd_data)

#Variable A.G.
fligner.test(A.G  ~ Padece , data = ilpd_data)

```

Después de estudiar todas las variables, vemos que de todas, solo par las variables* Edad,TP,Albumin y A.G *, se acepta la Hipótesis Nula de que las varianzas de ambas muestras son iguales.



## 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

### Correlación
Dado que queremos conocer si un paciente padece o no de Hígado, vamos a comprobar cual es la correlación de la variable dependiente **Padece** con cada una de las variables independientes existentes en el Dataset.

```{r}
corr <- cor(ilpd_data[, c('edad', 'padece', 'hombre', 'TB', 'DB', 'alk_phos', 'alamine', 'TP', 'albumin', 'A.G')])
```

```{r}
ggcorrplot(corr, outline.col = "black", lab=TRUE)
```
Si nos fijamos en la correlación de las variables existentes con la variable dependiente de padecer enfermedad, podemos observar como no existe una fuerte correlación entre esta y el resto de las variables. Fijandonos en los valores de correlación podemos extraer la siguiente información:

- La edad influye muy levemente en la posibilidad de padecer, a medida que aumenta la edad, existe un ligero aumento en la posibilidad de padecer de Hígado.
- El ser hombre o mujer no tiene prácticamente correlación con la variable, ocurre lo mismo con la variable TP.
- Las variables TB y DB son las que tienen una mayor correlación directa con padecer, a medida que aumentan estas variables puede ser posible que aumenten los casos de paceder de Hígado.
- Por el contrario las variables de albumina y AG tienen una correlación inversa, a medida que estas tienen un valor mayor, el número de casos que padecen de Hígado disminuyen.

Adicionalmente podemos observar como las variables TB y DB se encuentran fuertemente relacionadas entre si, así como las variables de albumina con TP y albumina con AG.

Al mostrar un gráfico de coordenadas, se puede ver como en estas relaciones, existe una tendencia de los valores a mantenerse en la diagonal, lo que nos hace indicar que existe una relación entre las mismas.

```{r}
plot(ilpd_data$TB, ilpd_data$DB)
plot(ilpd_data$albumin, ilpd_data$TP)
plot(ilpd_data$albumin, ilpd_data$A.G)
```

### Contraste de hipótesis.

En este apartado vamos a responder a la pregunta de si las personas de menos de 40 años tienen la alumina superior a las personas de más de 40 años. 

Para ello en primer lugar escribimos la hipótesis nula y alternativa.
$$
H_0: \mu_{menos40} = \mu_{mas40}
\\
H_1: \mu_{menos40} > \mu_{mas40}
$$
Podemos comprobar gráficamente como se distribuye la albumina según el intervalo indicado. A primera vista puede parece que a niveles más altos de albumina se tiene menos edad. 

```{r}
ilpd_data['menos_40'] <- ilpd_data$edad < 40
ggplot(ilpd_data,aes(x=albumin,col=menos_40)) + geom_density()
```

Para conocer que test debemos aplicar en primer lugar debemos comprobar si la variable **alumina** sigue una distribución normal, dado que el número de elementos existentes en la muestra es de 583, por el teorema del límite central podemos suponer que así es.

Además hemos de comprobar si la varianza de ambas medidas es diferente
```{r}
var.test( ilpd_data$albumin[ilpd_data$edad < 40], ilpd_data$albumin[ilpd_data$edad >= 40] )
```

Observando el p-value se observa como es superior a 0.05, por lo tanto descartamos igualdad de varianzas en las dos poblaciones.

En consecuencia, aplicamos un test de dos muestras independientes sobre la media con varianza desconocida y diferente. Es un test unilateral por la derecha.

```{r}
t.test( ilpd_data$albumin[ilpd_data$edad < 40], ilpd_data$albumin[ilpd_data$edad >= 40], var.equal=FALSE, alternative = "greater")
```

El valor de p es 1.721e-09, el cual es muy inferior a 0.05, por lo tanto se rechaza la hipótesis nula y podemos concluir que el nivel de albumina es superior en los pacientes que tienen menos de 40 años.

### Método Regresión

En este apartado vamos a realizar un modelo de regresión para comprobar si una persona en base a sus atributos tiene posibilidades de sufrir afección de hígado.
Para realizar el modelo vamos a realizar una aproximación creciente, es decir, dado que el número de variables independientes o factores es comedido podemos ir añadiendo
factores nuevos al modelo hasta alcanzar aquel que nos ofrezca un mejor resultado.
Para medir cual de los modelos se adapta mejor a los datos utilizaremos el valor AIC, el cual a menor valor mejor se adapta el modelo.

```{r}
glm(Padece ~ edad, data=ilpd_data, family=binomial(link=logit))$aic
glm(Padece ~ edad + TB, data=ilpd_data, family=binomial(link=logit))$aic
glm(Padece ~ edad + TB + DB, data=ilpd_data, family=binomial(link=logit))$aic
glm(Padece ~ edad + TB + DB + alk_phos, data=ilpd_data, family=binomial(link=logit))$aic
glm(Padece ~ edad + TB + DB + alk_phos + alamine, data=ilpd_data, family=binomial(link=logit))$aic
glm(Padece ~ edad + TB + DB + alk_phos + alamine + aspartate , data=ilpd_data, family=binomial(link=logit))$aic
glm(Padece ~ edad + TB + DB + alk_phos + alamine + aspartate + TP, data=ilpd_data, family=binomial(link=logit))$aic
glm(Padece ~ edad + TB + DB + alk_phos + alamine + aspartate + TP + albumin, data=ilpd_data, family=binomial(link=logit))$aic
glm(Padece ~ edad + TB + DB + alk_phos + alamine + aspartate + TP + albumin + A.G, data=ilpd_data, family=binomial(link=logit))$aic
```

Como se puede observar el modelo que ofrece mejores resultados es aquel que tiene los factores **edad**,**TB**,**DB**, **alk_phos**, **alamine**, **aspartate**, **TP** y **albumin**.
A continuación vamos a calcular un resumen del modelo para comprobar cuales son los coeficientes y el p-value de cada uno de los factores.

```{r}
model.logit <- glm(Padece ~ edad + TB + DB + alk_phos + alamine + aspartate + TP + albumin + A.G, data=ilpd_data, family=binomial(link=logit))
summary(model.logit)
```

Observamos como los factores **TB**, **alk_pho**, **aspartate** y **A.G** tienen un p-value mayor a 0.05, por lo tanto son atributos no significativos y pueden ser eliminados del modelo.

```{r}
model.logit <- glm(Padece ~ edad + DB + alamine + TP + albumin, data=ilpd_data, family=binomial(link=logit))
summary(model.logit)
```

Una vez eliminados los factores no significativos se observa como el valor de **AIC** ha disminuido a 591.46 por lo que lo podemos considerar como el mejor modelo que podemos obtener.

Para comprobar el comportamiento del modelo vamos a relizar un test de bondad de ajuste. Debido a que las variables explicativas son continuas, vamos a utilizar el **Test de Hosmer-Lemeshow**.

En este test se comparan los valores previstos por el modelo con los valores obtenidos, siendo la hipotesis nula la no existencia de diferencias entre los valores observados y los previstos.
```{r}
actual=as.data.frame(to.dummy(ilpd_data$Padece,"si_padece"))
actual=actual$si_padece.si_padece
hoslem.test(actual, fitted(model.logit))
```

Según el valor obtenido el p-value es de 0.81 el cual es superior a 0.05 por lo tanto no se rechaza la hipótesis nula y podemos asegurar con un 95% que los valores previstos se asemejan a los valores obtenidos.

# 5. Representación de los resultados a partir de tablas y gráficas.

## Tablas y gráficas modelo regresión.

### Odd-Ratio
En este punto vamos a calcular cual es el odd-ratio de cada uno de los factores que utilizamos en el modelo de regresión para calcular si una persona puede sufrir afecciones de hígado.
```{r}
exp(coefficients(model.logit))
```

Según los datos obtenidos podemos deducir que:
- La edad afecta a la afección positivamente, a mayor edad la probabilidad de sufrir de hígado aumenta. En este caso, por cada unidad que aumenta la edad, la probabilidad aumenta en un 1.8%.
- El DB afecta a la afección positivamente, por cada unidad aumentada de DB la probabilidad aumenta en un 72%.
- La alamina afecta a la afección positivamente, por cada unidad aumentada de alamina la probabilidad aumenta en un 1.5%.
- La TP afecta a la afección positivamente, por cada unidad aumentada de TP la probabilidad aumenta en un 54%.
- La albumina afecta a la afección negativamente, por cada unidad aumentada de albumina la probabilidad disminuye en un 51%.

### Matriz de confusión
```{r}
predicciones <- factor(ifelse(test = model.logit$fitted.values > 0.5, yes="si_padece", no="no_padece"))
caret::confusionMatrix(ilpd_data$Padece, predicciones, positive="si_padece")
```

Al observar la matriz de confusión observamos como la exactitud del modelo se encuentra en un 72.9%, Esto quiere decir que en un 72.9% el modelo acierta en su predicción.
También podemos observar la sensibilidad del modelo, el número de veces que el modelo indica que si_padece y el valor real es si_padece_, el cual es de un 75%, por lo que el modelo es capaz de encontrar la mayoría de los casos en los cuales un paciente si sufre de afección de higado.
Al observar la especificidad podemos ver como su valor es de un 56%, este valor indica el número de veces que el modelo indica que no se padece una afección cuando en verdad no se padece. En este caso el modelo predice el valor correcto únicamente en el 56% de los casos, dando un alto porcentaje de falsos negativos, lo cual a la hora de dar un diagnóstico es preocupante, ya que un 44% de los resultados negativos no serían realmente negativos sino que el paciente si estaría sufriendo de higado. 

```{r}
p <- predict(model.logit, ilpd_data[, c("edad","DB","alamine","TP","albumin" )], type="response")
r <- roc(ilpd_data$Padece, p, data=ilpd_data)
plot(r)
```
```{r}
auc(r)
```

Dado que el area debajo de la curva es de un 0.75, podemos decir que el modelo discrimina de manera adecuada los datos, pero se encuentra lejos del valor
0.8, a partir del cual se consideraría como una discriminación excelente.


# 6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

A la vista de los resultados obtenidos a lo largo del documento podemos extraer las siguientes conclusiones:

- La **edad** y el **sexo** no son unos atributos importantes para la detección de un problema de hígado. Aún así al observar los **odd-values** del modelo de regresión realizado, se comprueba como el valor de edad es de 1.01, esto puede dar lugar a dos interpretaciones: La edad es totalmente independiente de la probabilidad de padecer la enfermedad o la probabilidad aumenta muy levemente a medida que la edad aumenta. Además se ha comprobado mediante un **contraste de hipótesis** que la edad no es un factor a tener en cuenta para comprobar la enfermedad ya que no existen evidencias suficientes para suponer que un aumento de edad aumente el factor de riesgo.
- Si queremos conocer cuales son los atributos que más probabilidades nos dan de saber si un paciente subre de un problema de hígado nos debemos de fijar en aquellos que tengan los niveles más altos de **DB** y **TP**, a niveles más altos de estos valores mayor es la probabilidad de sufrir un problema de hígado. También tiene sentido que ambos valores afecten a la probabilidad ya que ambos se encuentran relacionados.
- Los valores altos de **albumina** disminuyen la probabilidad de paceder, por lo tanto si nos interesa conocer si un paciente no pacede, deberíamos buscar aquellos pacientes con alta albumina y baja **DB** y **TP**. Igualmente la albumina se encuentra fuertemente relacionada con los atributos  **AG **y **TB**, por lo que la observación de ambos también podría ser interesante para comprobar el padecimiento del paciente.

- Al generar un modelo de regresión se han descubierto que las variables independientes con mayor significancia son edad, **DB**, **alamine**, **TP** y **albumina.** Con dicho modelo se alcanza una exactitud del 73%, teniendo una exactitud del 75%, la cual se puede considerar como bastante alta. Aún así el valor de especificidad es del 56% por lo que la mayoría de los negativos no se consideran como tal, por lo tanto habría que refinar el modelo con el fin de aumentar dicho porcentaje.

En base a estas conclusiones podemos concluir con que se ha respondido al problema que se planteaba en un principio, **clasificación de pacientes para saber si sufre de Hígado**. Se ha realizado un modelo de regresión para realizar la clasificación, consiguiendo un 73% de exactitud, y se han identificado cuales son los parámetros más influyentes a la hora de clasificar a los pacientes según su patología.

# 7. Contribución al Documento
    

| Contribuciones| Firma|
| -- | -- | 
| Investigación previa| JJMC, LVE  | 
| Redacción de respuestas| JJMC, LVE | 
| Desarrollo de código| JJMC, LVE | 
